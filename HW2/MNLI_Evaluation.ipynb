{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "%matplotlib inline\n",
    "import pickle as pkl\n",
    "from tqdm import tqdm_notebook\n",
    "random.seed(134)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change labels\n",
    "def change_label(label):\n",
    "    if label == 'neutral':\n",
    "        return 0.0\n",
    "    elif label == 'entailment':\n",
    "        return 1.0\n",
    "    elif label == 'contradiction':\n",
    "        return 2.0\n",
    "    \n",
    "def split_file_token(file):\n",
    "    file_ls = []\n",
    "    y = []\n",
    "    with open(file) as fd:\n",
    "        rd = csv.reader(fd, delimiter=\"\\t\", quotechar=' ')\n",
    "        for row in rd:\n",
    "            if row[0] == 'sentence1':\n",
    "                pass\n",
    "            else:\n",
    "                file_ls.append([row[0].split(),row[1].split(),row[3]])\n",
    "                y.append(change_label(row[2]))\n",
    "    return file_ls,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnli_val_path = \"hw2_data/mnli_val.tsv\"      \n",
    "mnli_val_token,mnli_val_y = split_file_token(mnli_val_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['fiction', 'government', 'slate', 'telephone', 'travel'],\n",
       "      dtype='<U10')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genres_val = [mnli_val_token[i][2] for i in range(len(mnli_val_token))]\n",
    "genres = np.unique(genres_val)\n",
    "genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4bffb6f6b284242a2fc706679befbb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def tokenizer_dt(tokenizer_pair):\n",
    "    premise = []\n",
    "    hypothesis = []\n",
    "    for i in tokenizer_pair:\n",
    "        premise.append(i[0])\n",
    "        hypothesis.append(i[1])\n",
    "    return premise,hypothesis\n",
    "\n",
    "#build vocabulary dictionary\n",
    "PAD_IDX = 0\n",
    "UNK_IDX = 1\n",
    "Emb_Mtx = []\n",
    "mnli_train_token2id = {}\n",
    "mnli_train_id2token = {}\n",
    "        \n",
    "words_to_load = 60000    \n",
    "with open('wiki-news-300d-1M.vec') as f:\n",
    "    Emb_Mtx = np.zeros((words_to_load+2, 300))\n",
    "    Emb_Mtx[UNK_IDX] = np.ones(300)\n",
    "    mnli_train_token2id['<pad>'] = PAD_IDX \n",
    "    mnli_train_token2id['<unk>'] = UNK_IDX\n",
    "    mnli_train_id2token[PAD_IDX] = '<pad>'\n",
    "    mnli_train_id2token[UNK_IDX] = '<unk>'\n",
    "    for i, line in tqdm_notebook(enumerate(f)):\n",
    "        if i >= words_to_load: \n",
    "            break\n",
    "        s = line.split()\n",
    "        Emb_Mtx[i+2, :] = np.asarray(s[1:])\n",
    "        mnli_train_token2id[s[0]] = i+2\n",
    "        mnli_train_id2token[i+2] = s[0]\n",
    "\n",
    "#get index\n",
    "def token2index(tokens_data,token_id):\n",
    "    indices_data = []\n",
    "    for tokens in tokens_data:\n",
    "        index_list = [token_id[token] if token in token_id else UNK_IDX for token in tokens]\n",
    "        indices_data.append(index_list)\n",
    "    return indices_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Emb_Mtx = torch.from_numpy(Emb_Mtx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SENTENCE_LENGTH = 30\n",
    "BATCH_SIZE = 32\n",
    "class SNLIDataset(Dataset):\n",
    "    def __init__(self, data_list1, data_list2, target_list):\n",
    "        \n",
    "        self.data_list1 = data_list1\n",
    "        self.data_list2 = data_list2\n",
    "        self.target_list = target_list\n",
    "        \n",
    "        assert (len(self.data_list1) == len(self.target_list))\n",
    "        assert (len(self.data_list2) == len(self.target_list))\n",
    "\n",
    "    def __len__(self):\n",
    "        #return len(self.data_list1)\n",
    "        return len(self.target_list)\n",
    "        \n",
    "    def __getitem__(self, key):\n",
    "        token_idx1 = self.data_list1[key][:MAX_SENTENCE_LENGTH]\n",
    "        token_idx2 = self.data_list2[key][:MAX_SENTENCE_LENGTH]\n",
    "        label = self.target_list[key]\n",
    "        return [token_idx1, len(token_idx1),token_idx2, len(token_idx2), label]\n",
    "    \n",
    "def MNLI_collate_func(batch):\n",
    "    data_list1 = []\n",
    "    data_list2 = []\n",
    "    label_list = []\n",
    "    length_list1 = []\n",
    "    length_list2 = []\n",
    "    for datum in batch:\n",
    "        label_list.append(datum[4])\n",
    "        length_list1.append(datum[1])\n",
    "        length_list2.append(datum[3])\n",
    "    for datum in batch:\n",
    "        padded_vec1 = np.pad(np.array(datum[0]), \n",
    "                                pad_width=((0,MAX_SENTENCE_LENGTH-datum[1])), \n",
    "                                mode=\"constant\", constant_values=0)\n",
    "        data_list1.append(padded_vec1)\n",
    "        \n",
    "        padded_vec2 = np.pad(np.array(datum[2]), \n",
    "                             pad_width=((0,MAX_SENTENCE_LENGTH-datum[3])), \n",
    "                             mode=\"constant\", constant_values=0)\n",
    "        data_list2.append(padded_vec2)\n",
    "        \n",
    "    return [torch.from_numpy(np.array(data_list1)).cuda(), torch.LongTensor(length_list1).cuda(), \n",
    "            torch.from_numpy(np.array(data_list2)).cuda(), torch.LongTensor(length_list2).cuda(), \n",
    "            torch.LongTensor(label_list).cuda()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genre_cut(genre):\n",
    "    ind_val = [i for i, x in enumerate(genres_val) if x == genre]\n",
    "\n",
    "    val_genre_x = [[mnli_val_token[i][0],mnli_val_token[i][1]] for i in ind_val]\n",
    "    val_genre_y = [mnli_val_y[i] for i in ind_val]\n",
    "    \n",
    "    val_pre,val_hyp = tokenizer_dt(val_genre_x)\n",
    "    \n",
    "    indices_val_pre = token2index(val_pre,mnli_train_token2id)\n",
    "    indices_val_hyp = token2index(val_hyp,mnli_train_token2id)\n",
    "\n",
    "    val_dataset = SNLIDataset(indices_val_pre,indices_val_hyp, val_genre_y)\n",
    "    val_loader = torch.utils.data.DataLoader(dataset=val_dataset,\n",
    "                                             batch_size=BATCH_SIZE,\n",
    "                                             collate_fn=MNLI_collate_func,\n",
    "                                             shuffle=True)\n",
    "\n",
    "    return val_loader,val_genre_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, hidden_size1, hidden_size2,size, num_layers, num_classes, emb_size=300):\n",
    "\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.num_layers, self.size = num_layers, size\n",
    "        self.hidden_size1,self.hidden_size2 = hidden_size1, hidden_size2\n",
    "        \n",
    "        self.embedding = nn.Embedding.from_pretrained(Emb_Mtx).float()\n",
    "       \n",
    "        self.rnn1 = nn.GRU(emb_size, hidden_size1, num_layers, batch_first = True, bidirectional = True)\n",
    "        self.rnn2 = nn.GRU(emb_size, hidden_size2, num_layers, batch_first = True, bidirectional = True)  \n",
    "        \n",
    "        self.linear1 = nn.Linear(hidden_size1 + hidden_size2, size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(size, num_classes)\n",
    "\n",
    "    def init_hidden(self, batch_size, hidden_size):\n",
    "        hidden = torch.randn(self.num_layers * 2 , batch_size, hidden_size).cuda()\n",
    "        return hidden\n",
    "\n",
    "    def forward(self, x1, lengths1, x2, lengths2):\n",
    "        \n",
    "        # reset hidden state\n",
    "        batch_size1, seq_len1 = x1.size()\n",
    "        batch_size2, seq_len2 = x2.size()\n",
    "        \n",
    "        self.hidden1 = self.init_hidden(batch_size1,self.hidden_size1)\n",
    "        self.hidden2 = self.init_hidden(batch_size2,self.hidden_size2)\n",
    "\n",
    "        # get embedding of characters\n",
    "        embed1 = self.embedding(x1)\n",
    "        embed2 = self.embedding(x2)\n",
    " \n",
    "        # no pack padded sequence\n",
    "    \n",
    "        # fprop though RNN\n",
    "        rnn_out1, self.hidden1 = self.rnn1(embed1, self.hidden1)\n",
    "        rnn_out2, self.hidden2 = self.rnn2(embed2, self.hidden2)\n",
    "        \n",
    "        # sum hidden activations of RNN across time\n",
    "        cat_out = torch.cat([self.hidden1,self.hidden2],dim = -1) \n",
    "        rnn_out = torch.sum(cat_out, dim=0)\n",
    "        rnn_out = self.linear1(rnn_out)\n",
    "        rnn_out = self.relu(rnn_out)\n",
    "        logits = self.linear2(rnn_out)\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self,k_size,p_size, hidden_size,size2, num_layers, num_classes,emb_size =300):\n",
    "\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        self.num_layers, self.hidden_size, self.size2 = num_layers, hidden_size, size2\n",
    "        self.k_size,self.p_size = k_size, p_size\n",
    "        \n",
    "        self.embedding = nn.Embedding.from_pretrained(Emb_Mtx).float()\n",
    "    \n",
    "        self.conv1 = nn.Conv1d(emb_size, hidden_size, kernel_size=k_size, padding=p_size)\n",
    "        self.conv2 = nn.Conv1d(hidden_size, hidden_size, kernel_size=k_size, padding=p_size)\n",
    "        self.conv3 = nn.Conv1d(emb_size, hidden_size, kernel_size=k_size, padding=p_size)\n",
    "        self.conv4 = nn.Conv1d(hidden_size, hidden_size, kernel_size=k_size, padding=p_size)\n",
    "        \n",
    "        self.maxpool1 = nn.MaxPool1d(MAX_SENTENCE_LENGTH)\n",
    "        self.maxpool2 = nn.MaxPool1d(MAX_SENTENCE_LENGTH)\n",
    "        \n",
    "        self.linear1 = nn.Linear(2*hidden_size, size2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(size2, num_classes)\n",
    "\n",
    "    def forward(self, x1, lengths1, x2, lengths2):\n",
    "        batch_size1, seq_len1 = x1.size()\n",
    "        batch_size2, seq_len2 = x2.size()\n",
    "\n",
    "        embed1 = self.embedding(x1)\n",
    "        embed2 = self.embedding(x2)\n",
    "        \n",
    "        hidden1 = self.conv1(embed1.transpose(1,2)).transpose(1,2)\n",
    "        hidden2 = self.conv3(embed2.transpose(1,2)).transpose(1,2)\n",
    "        \n",
    "        hidden1 = F.relu(hidden1.contiguous().view(-1, hidden1.size(-1))).view(batch_size1, seq_len1, hidden1.size(-1))\n",
    "        hidden2 = F.relu(hidden2.contiguous().view(-1, hidden2.size(-1))).view(batch_size2, seq_len2, hidden2.size(-1))\n",
    "\n",
    "        hidden1 = self.conv2(hidden1.transpose(1,2)).transpose(1,2)\n",
    "        hidden2 = self.conv4(hidden2.transpose(1,2)).transpose(1,2)\n",
    "        \n",
    "        hidden1 = F.relu(hidden1.contiguous().view(-1, hidden1.size(-1))).view(batch_size1, hidden1.size(-1), seq_len1)\n",
    "        hidden2 = F.relu(hidden2.contiguous().view(-1, hidden2.size(-1))).view(batch_size2, hidden2.size(-1), seq_len2)\n",
    "\n",
    "        hidden1 = self.maxpool1(hidden1)\n",
    "        hidden2 = self.maxpool2(hidden2)\n",
    "        \n",
    "        # sum hidden activations of CNN across time\n",
    "        cat_out = torch.cat([hidden1,hidden2],dim = 1) \n",
    "\n",
    "        rnn_out = torch.sum(cat_out, dim = -1)\n",
    "        \n",
    "        rnn_out = self.linear1(rnn_out)\n",
    "        rnn_out = self.relu(rnn_out)\n",
    "        logits = self.linear2(rnn_out)\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(loader, model):\n",
    "    \"\"\"\n",
    "    Help function that tests the model's performance on a dataset\n",
    "    @param: loader - data loader for the dataset to test against\n",
    "    \"\"\"\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    for data1, lengths1, data2, lengths2, labels in loader:\n",
    "        data_batch1, lengths_batch1, label_batch = data1, lengths1, labels\n",
    "        data_batch2, lengths_batch2 = data2, lengths2\n",
    "        outputs = F.softmax(model(data_batch1, lengths_batch1,data_batch2, lengths_batch2), dim=1)\n",
    "        predicted = outputs.max(1, keepdim=True)[1]\n",
    "\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels.view_as(predicted)).sum().item()\n",
    "    return (100 * correct / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fic_val_loader,fic_val_genre_y = genre_cut('fiction')\n",
    "gov_val_loader,gov_val_genre_y = genre_cut('government')\n",
    "sla_val_loader,sla_val_genre_y = genre_cut('slate')\n",
    "tel_val_loader,tel_val_genre_y = genre_cut('telephone')\n",
    "tra_val_loader,tra_val_genre_y = genre_cut('travel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Fiction Val acc of best CNN: 30.65\n",
      "For Government Val acc of best CNN: 29.33\n",
      "For Slate Val acc of best CNN: 35.03\n",
      "For Telephone Val acc of best CNN: 29.33\n",
      "For Travel Val acc of best CNN: 30.75\n"
     ]
    }
   ],
   "source": [
    "model = CNN(k_size = 3,p_size=1,hidden_size = 200,size2 = 100, num_layers = 2, num_classes = 3)\n",
    "model.cuda()\n",
    "\n",
    "print(\"For Fiction Val acc of best CNN: {}\".format(round(test_model(fic_val_loader, model),2)))\n",
    "print(\"For Government Val acc of best CNN: {}\".format(round(test_model(gov_val_loader, model),2)))\n",
    "print(\"For Slate Val acc of best CNN: {}\".format(round(test_model(sla_val_loader, model),2)))\n",
    "print(\"For Telephone Val acc of best CNN: {}\".format(round(test_model(gov_val_loader, model),2)))\n",
    "print(\"For Travel Val acc of best CNN: {}\".format(round(test_model(tra_val_loader, model),2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Fiction Val acc of best RNN: 34.27\n",
      "For Government Val acc of best RNN: 33.96\n",
      "For Slate Val acc of best RNN: 30.14\n",
      "For Telephone Val acc of best RNN: 33.96\n",
      "For Travel Val acc of best RNN: 34.01\n"
     ]
    }
   ],
   "source": [
    "model = RNN(hidden_size1 = 150, hidden_size2 = 150,size = 50, num_layers = 1, num_classes = 3)\n",
    "model.cuda()\n",
    "\n",
    "print(\"For Fiction Val acc of best RNN: {}\".format(round(test_model(fic_val_loader, model),2)))\n",
    "print(\"For Government Val acc of best RNN: {}\".format(round(test_model(gov_val_loader, model),2)))\n",
    "print(\"For Slate Val acc of best RNN: {}\".format(round(test_model(sla_val_loader, model),2)))\n",
    "print(\"For Telephone Val acc of best RNN: {}\".format(round(test_model(gov_val_loader, model),2)))\n",
    "print(\"For Travel Val acc of best RNN: {}\".format(round(test_model(tra_val_loader, model),2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
