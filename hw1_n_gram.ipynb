{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jiahuiyuan/anaconda/lib/python3.6/site-packages/sklearn/utils/fixes.py:313: FutureWarning: numpy not_equal will not check object identity in the future. The comparison did not return the same result as suggested by the identity (`is`)) and will change.\n",
      "  _nan_object_mask = _nan_object_array != _nan_object_array\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import spacy\n",
    "import string\n",
    "from nltk.util import ngrams\n",
    "from tqdm import tqdm_notebook\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_pos_txt = glob.glob(\"/Users/xinyangqiu/Downloads/aclImdb/train/pos/*.txt\")\n",
    "train_neg_txt = glob.glob(\"/Users/xinyangqiu/Downloads/aclImdb/train/neg/*.txt\")\n",
    "test_pos_txt = glob.glob(\"/Users/xinyangqiu/Downloads/aclImdb/test/pos/*.txt\")\n",
    "test_neg_txt = glob.glob(\"/Users/xinyangqiu/Downloads/aclImdb/test/neg/*.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_txt(txt,ls):\n",
    "    for fle in txt:\n",
    "        with open(fle) as f:\n",
    "            ls.append(f.read())\n",
    "    return len(txt)\n",
    "    \n",
    "train_x = []\n",
    "num_train_pos = read_txt(train_pos_txt,train_x)\n",
    "num_train_neg = read_txt(train_neg_txt,train_x)\n",
    "train_y = [1] * num_train_pos + [0] * num_train_neg\n",
    "\n",
    "test_x = []\n",
    "num_test_pos = read_txt(test_pos_txt,test_x)\n",
    "num_test_neg = read_txt(test_neg_txt,test_x)\n",
    "test_y = [1] * num_test_pos + [0] * num_test_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random.Random(4).shuffle(train_x)\n",
    "random.Random(4).shuffle(train_y)\n",
    "\n",
    "val_x = train_x[:5000]\n",
    "val_y =train_y[:5000]\n",
    "train_x = train_x[5000:]\n",
    "train_y = train_y[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer = spacy.load('en_core_web_sm')\n",
    "punctuations = string.punctuation\n",
    "def tokenize(sent):\n",
    "  tokens = tokenizer(sent)\n",
    "  return [token.text.lower() for token in tokens if (token.text not in punctuations)]\n",
    "\n",
    "def tokenizer_dt(dataset):\n",
    "    token_dataset = []\n",
    "    all_tokens = []\n",
    "    for sample in tqdm_notebook(tokenizer.pipe(dataset, disable=['parser', 'tagger', 'ner'], batch_size=512, n_threads=1)):\n",
    "        tokens = [token.text.lower() for token in sample if (token.text not in punctuations)]\n",
    "        token_dataset.append(tokens)\n",
    "        all_tokens += tokens\n",
    "    return token_dataset, all_tokens\n",
    "\n",
    "def tokenizer_gram(dataset,n):\n",
    "    gram_dataset = []\n",
    "    all_grams = [] \n",
    "    for i in tqdm_notebook(dataset):\n",
    "        token_gram = list(ngrams(i,n))\n",
    "        gram_dataset.append(token_gram)\n",
    "        all_grams += token_gram\n",
    "    return gram_dataset, all_grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e203395ab174a018e8943483c22e76a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c56ec614f3e1483fa4b834233f3e7eb9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8900e8167ff4c7288ad75db98befcc4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#words\n",
    "token_train, all_train_tokens = tokenizer_dt(train_x)\n",
    "token_test, all_test_tokens = tokenizer_dt(test_x)\n",
    "token_val, all_val_tokens = tokenizer_dt(val_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c669e439a444ff4bea0965f3fae84c9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e420c0815294f9891485fe751600152"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "797d479b907d49fda70c4276ee30be91"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa733fbe58dd46309835e809d8e9dcae"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6506c3c30f264711ab993225d3f872f5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df695b06cd8a47eb8b288a45ff385cc3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ad0b531a8c044ceac48ef5f7965ce22"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f22c6a637c9d4ad187e36eda58690d12"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39e38c96a77f4f33a2a55b624247de66"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#creat 2-grams\n",
    "bigram_val, all_bigrams_val = tokenizer_gram(token_val,2)\n",
    "bigram_train, all_bigrams_train = tokenizer_gram(token_train,2)\n",
    "bigram_test, all_bigrams_test = tokenizer_gram(token_test,2)\n",
    "#creat 3-grams\n",
    "\n",
    "trigram_val, all_trigrams_val = tokenizer_gram(token_val,3)\n",
    "trigram_train, all_trigrams_train = tokenizer_gram(token_train,3)\n",
    "trigram_test, all_trigrams_test = tokenizer_gram(token_test,3)\n",
    "#creat 4-grams\n",
    "quagram_val, all_quagrams_val = tokenizer_gram(token_val,4)\n",
    "quagram_train, all_quagrams_train = tokenizer_gram(token_train,4)\n",
    "quagram_test, all_quagrams_test = tokenizer_gram(token_test,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_vocab_size = 10000\n",
    "PAD_IDX = 0\n",
    "UNK_IDX = 1\n",
    "\n",
    "def build_vocab(all_tokens):\n",
    "    token_counter = Counter(all_tokens)\n",
    "    vocab, count = zip(*token_counter.most_common(max_vocab_size))\n",
    "    id2token = list(vocab)\n",
    "    token2id = dict(zip(vocab, range(2,2+len(vocab)))) \n",
    "    id2token = ['<pad>', '<unk>'] + id2token\n",
    "    token2id['<pad>'] = PAD_IDX \n",
    "    token2id['<unk>'] = UNK_IDX\n",
    "    return token2id, id2token\n",
    "\n",
    "def token2index_dataset(tokens_data,token_id):\n",
    "    indices_data = []\n",
    "    for tokens in tqdm_notebook(tokens_data):\n",
    "        index_list = [token_id[token] if token in token_id else UNK_IDX for token in tokens]\n",
    "        indices_data.append(index_list)\n",
    "    return indices_data\n",
    "\n",
    "def get_dt_indices(all_train_dt,token_train_dt,token_test_dt,token_val_dt):\n",
    "    token2id, id2token = build_vocab(all_train_dt)\n",
    "    train_data_indices = token2index_dataset(token_train_dt,token2id)\n",
    "    test_data_indices = token2index_dataset(token_test_dt,token2id)\n",
    "    val_data_indices = token2index_dataset(token_val_dt,token2id)\n",
    "    return train_data_indices,test_data_indices,val_data_indices, id2token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f572b29880ff4e01b71c8831b2659c9a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b50648da88f4798a52cb79f3f820608"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ded74b4afe3b4be8abfc65b545be4d05"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75465cd70fcd4322989ab782b10a4fa3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06f70b09159b40518f81baf8c1f53e0f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a16f92d2d454aacb08865126315fe1b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f263cfdd7c14d89923a412404f70625"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59f21e75766746d4a734e4f113c8ac28"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "514d093e74e6425982b7be2ce94115a9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87009753f66b4903834e18aefec23bec"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b72fcc5a8eb43b197f0653eb7042a8a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24639961939044f48601745c62ec6fc5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data_indices1,test_data_indices1,val_data_indices1, id2token1 = get_dt_indices(all_train_tokens,token_train,token_test,token_val)\n",
    "train_data_indices2,test_data_indices2,val_data_indices2,id2token2= get_dt_indices(all_bigrams_train,bigram_train,bigram_test,bigram_val)\n",
    "train_data_indices3,test_data_indices3,val_data_indices3,id2token3 = get_dt_indices(all_trigrams_train,trigram_train,trigram_test,trigram_val)\n",
    "train_data_indices4,test_data_indices4,val_data_indices4,id2token4 = get_dt_indices(all_quagrams_train,quagram_train,quagram_test,quagram_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#MAX_SENTENCE_LENGTH = 400\n",
    "class NewsGroupDataset(Dataset):\n",
    "    def __init__(self, data_list, target_list):\n",
    "        self.data_list = data_list\n",
    "        self.target_list = target_list\n",
    "        assert (len(self.data_list) == len(self.target_list))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "        \n",
    "    def __getitem__(self, key):\n",
    "        token_idx = self.data_list[key][:MAX_SENTENCE_LENGTH]\n",
    "        label = self.target_list[key]\n",
    "        return [token_idx, len(token_idx), label]\n",
    "\n",
    "def newsgroup_collate_func(batch):\n",
    "    data_list = []\n",
    "    label_list = []\n",
    "    length_list = []\n",
    "    for datum in batch:\n",
    "        label_list.append(datum[2])\n",
    "        length_list.append(datum[1])\n",
    "    for datum in batch:\n",
    "        padded_vec = np.pad(np.array(datum[0]), \n",
    "                                pad_width=((0,MAX_SENTENCE_LENGTH-datum[1])), \n",
    "                                mode=\"constant\", constant_values=0)\n",
    "        data_list.append(padded_vec)\n",
    "    return [torch.from_numpy(np.array(data_list)), torch.LongTensor(length_list), torch.LongTensor(label_list)]\n",
    "def data_loader(BATCH_SIZE,indices,y,shuffle_ind):\n",
    "    new_set = NewsGroupDataset(indices,y)\n",
    "    return torch.utils.data.DataLoader(dataset=new_set, \n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=newsgroup_collate_func,\n",
    "                                           shuffle=shuffle_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BagOfWords(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_dim):\n",
    "        super(BagOfWords, self).__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, emb_dim, padding_idx=0)\n",
    "        self.linear = nn.Linear(emb_dim,20)\n",
    "    \n",
    "    def forward(self, data, length):\n",
    "        out = self.embed(data)\n",
    "        out = torch.sum(out, dim=1)\n",
    "        out /= length.view(length.size()[0],1).expand_as(out).float()\n",
    "        out = self.linear(out.float())\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_model(loader, model):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    for data, lengths, labels in loader:\n",
    "        data_batch, length_batch, label_batch = data, lengths, labels\n",
    "        outputs = F.softmax(model(data_batch, length_batch), dim=1)\n",
    "        predicted = outputs.max(1, keepdim=True)[1]\n",
    "        \n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels.view_as(predicted)).sum().item()\n",
    "    return (100 * correct / total)\n",
    "\n",
    "def output_model(emb_dim,learning_rate,num_epochs,id_token_dt,train_loader_dt,test_loader_dt,val_loader_dt):\n",
    "    model = BagOfWords(len(id_token_dt), emb_dim)\n",
    "    criterion = torch.nn.CrossEntropyLoss()  \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (data, lengths, labels) in enumerate(train_loader_dt):\n",
    "            model.train()\n",
    "            data_batch, length_batch, label_batch = data, lengths, labels\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(data_batch, length_batch)\n",
    "            loss = criterion(outputs, label_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        # validate every 100 iterations\n",
    "            if i > 0 and i % 100 == 0:\n",
    "                # validate\n",
    "                train_acc = test_model(train_loader_dt, model)\n",
    "                val_acc = test_model(val_loader_dt, model)\n",
    "                #print('Epoch: [{}/{}], Step: [{}/{}], Validation Acc: {}'.format( \n",
    "                #           epoch+1, num_epochs, i+1, len(train_loader_dt), val_acc))\n",
    "    #return [emb_dim,learning_rate,num_epochs,test_model(val_loader_dt, model),test_model(test_loader_dt, model)]\n",
    "    return [emb_dim,learning_rate,num_epochs,train_acc,val_acc]#,test_model(test_loader_dt, model)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sgd optimizer\n",
    "def output_model_sgd(emb_dim,learning_rate,num_epochs,id_token_dt,train_loader_dt,test_loader_dt,val_loader_dt):\n",
    "    model = BagOfWords(len(id_token_dt), emb_dim)\n",
    "    criterion = torch.nn.CrossEntropyLoss()  \n",
    "    #optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "    print(model.parameters())\n",
    "    for epoch in tqdm_notebook(range(num_epochs)):\n",
    "        for i, (data, lengths, labels) in enumerate(train_loader_dt):\n",
    "            model.train()\n",
    "            data_batch, length_batch, label_batch = data, lengths, labels\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(data_batch, length_batch)\n",
    "            loss = criterion(outputs, label_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        # validate every 100 iterations\n",
    "            if i > 0 and i % 100 == 0:\n",
    "                # validate\n",
    "                train_acc = test_model(train_loader_dt, model)\n",
    "                val_acc = test_model(val_loader_dt, model)\n",
    "                #print('Epoch: [{}/{}], Step: [{}/{}], Validation Acc: {}'.format( \n",
    "                #           epoch+1, num_epochs, i+1, len(train_loader_dt), val_acc))\n",
    "    #return [emb_dim,learning_rate,num_epochs,test_model(val_loader_dt, model),test_model(test_loader_dt, model)]\n",
    "    return [emb_dim,learning_rate,num_epochs,train_acc,val_acc]#,test_model(test_loader_dt, model)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object Module.parameters at 0x1b21a29620>\n",
      "[100, 0.025, 150, 81.135, 78.7]\n",
      "<generator object Module.parameters at 0x1b21a29620>\n",
      "[100, 0.035, 150, 83.185, 81.44]\n",
      "<generator object Module.parameters at 0x1b17522db0>\n",
      "[100, 0.045, 150, 84.99, 82.48]\n"
     ]
    }
   ],
   "source": [
    "#sgd_1_gram_lr\n",
    "learning_rate = [0.025, 0.035,0.045]\n",
    "\n",
    "for i in learning_rate:\n",
    "    temp = output_model_sgd(emb_dim = 100,learning_rate = i,num_epochs = 150,\n",
    "                            id_token_dt = id2token1,train_loader_dt = train_loader1,\n",
    "                            test_loader_dt = test_loader1,val_loader_dt=val_loader1)\n",
    "    print(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object Module.parameters at 0x1b1c0dc2b0>\n",
      "[100, 0.025, 150, 70.695, 70.34]\n",
      "<generator object Module.parameters at 0x1b174065c8>\n",
      "[100, 0.035, 150, 75.06, 74.02]\n",
      "<generator object Module.parameters at 0x1b17406728>\n",
      "[100, 0.045, 150, 74.3, 72.4]\n"
     ]
    }
   ],
   "source": [
    "#sgd_2_gram_lr\n",
    "learning_rate = [0.025, 0.035,0.045]\n",
    "\n",
    "for i in learning_rate:\n",
    "    temp = output_model_sgd(emb_dim = 100,learning_rate = i,num_epochs = 150,\n",
    "                            id_token_dt = id2token2,train_loader_dt = train_loader2,\n",
    "                            test_loader_dt = test_loader2,val_loader_dt=val_loader2)\n",
    "    print(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object Module.parameters at 0x1b17908728>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d9a5e75fac245d899a4319fe9500abd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100, 0.025, 250, 65.1, 64.78]\n",
      "<generator object Module.parameters at 0x1b1b7b46d0>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f714be4a7eb24d5ebf29ae111c793431"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100, 0.035, 250, 65.825, 64.56]\n",
      "<generator object Module.parameters at 0x1b1b7b4a98>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7213583875348ee8f92c940953d0d75"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100, 0.045, 250, 63.135, 62.24]\n"
     ]
    }
   ],
   "source": [
    "#sgd_3_gram_lr\n",
    "learning_rate = [0.025, 0.035,0.045]\n",
    "\n",
    "for i in learning_rate:\n",
    "    temp = output_model_sgd(emb_dim = 100,learning_rate = i,num_epochs = 250,\n",
    "                            id_token_dt = id2token3,train_loader_dt = train_loader3,\n",
    "                            test_loader_dt = test_loader3,val_loader_dt=val_loader3)\n",
    "    print(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object Module.parameters at 0x1b1746df10>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c61c0f63bbc746a5a36e9f1a642ddd71"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100, 0.025, 250, 56.005, 54.94]\n",
      "<generator object Module.parameters at 0x1b17008fc0>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "527bed58dcb34efda268914d97a5fdd0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100, 0.035, 250, 54.77, 54.4]\n",
      "<generator object Module.parameters at 0x1b17008fc0>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "570ad0993b65426f8452523274213fe7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100, 0.045, 250, 50.6, 50.22]\n"
     ]
    }
   ],
   "source": [
    "#sgd_4_gram_lr\n",
    "learning_rate = [0.025, 0.035,0.045]\n",
    "\n",
    "for i in learning_rate:\n",
    "    temp = output_model_sgd(emb_dim = 100,learning_rate = i,num_epochs = 250,\n",
    "                            id_token_dt = id2token4,train_loader_dt = train_loader4,\n",
    "                            test_loader_dt = test_loader4,val_loader_dt=val_loader4)\n",
    "    print(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8962a78c04ff4d54bcee5c54a26fac04"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#get general understanding of 1gram_10000\n",
    "MAX_SENTENCE_LENGTH = [50,100,200,300,400,500]\n",
    "learning_rate = [0.005,0.01,0.015,0.02,0.025,0.03,0.035,0.04,0.045,0.05,0.1 ]\n",
    "dim = [10,50,100,150,200]\n",
    "r_sen_rate = []\n",
    "for i in tqdm_notebook(MAX_SENTENCE_LENGTH):\n",
    "    MAX_SENTENCE_LENGTH = i\n",
    "    train_loader1 = data_loader(BATCH_SIZE=32,indices = train_data_indices1,y = train_y,shuffle_ind=True)\n",
    "    test_loader1 = data_loader(BATCH_SIZE=32,indices = test_data_indices1,y = test_y,shuffle_ind=True)\n",
    "    val_loader1 = data_loader(BATCH_SIZE=32,indices = val_data_indices1,y = val_y,shuffle_ind=False)\n",
    "    for j in learning_rate:\n",
    "        for k in dim:\n",
    "            temp = output_model(emb_dim = k,learning_rate = j,num_epochs = 2,\n",
    "                                id_token_dt = id2token1,train_loader_dt = train_loader1,\n",
    "                                test_loader_dt = test_loader1,val_loader_dt=val_loader1)\n",
    "            temp\n",
    "            temp.insert(0,i)\n",
    "            r_sen_rate.append(temp)\n",
    "a= r_sen_rate\n",
    "dt = pd.DataFrame(a, columns=['sen_len','emb_dim',\"learning_rate\",\"epochs\",'train_acc','val_acc'])\n",
    "dt.to_csv('1gram1_10000.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test max sentence length for 4-gram\n",
    "MAX_SENTENCE_LENGTH = 50\n",
    "train_loader4 = data_loader(BATCH_SIZE=32,indices = train_data_indices4,y = train_y,shuffle_ind=True)\n",
    "test_loader4 = data_loader(BATCH_SIZE=32,indices = test_data_indices4,y = test_y,shuffle_ind=True)\n",
    "val_loader4= data_loader(BATCH_SIZE=32,indices = val_data_indices4,y = val_y,shuffle_ind=False)\n",
    "a = output_model(emb_dim = 200,learning_rate = 0.01,num_epochs = 2,\n",
    "            id_token_dt = id2token4,train_loader_dt = train_loader4,\n",
    "            test_loader_dt = test_loader4,val_loader_dt=val_loader4)\n",
    "\n",
    "MAX_SENTENCE_LENGTH = 100\n",
    "train_loade4 = data_loader(BATCH_SIZE=32,indices = train_data_indices4,y = train_y,shuffle_ind=True)\n",
    "test_loader4 = data_loader(BATCH_SIZE=32,indices = test_data_indices4,y = test_y,shuffle_ind=True)\n",
    "val_loader4 = data_loader(BATCH_SIZE=32,indices = val_data_indices4,y = val_y,shuffle_ind=False)\n",
    "b = output_model(emb_dim = 200,learning_rate = 0.05,num_epochs = 2,\n",
    "            id_token_dt = id2token4,train_loader_dt = train_loader4,\n",
    "            test_loader_dt = test_loader4,val_loader_dt=val_loader4)\n",
    "\n",
    "MAX_SENTENCE_LENGTH = 150\n",
    "train_loader4 = data_loader(BATCH_SIZE=32,indices = train_data_indices4,y = train_y,shuffle_ind=True)\n",
    "test_loader4 = data_loader(BATCH_SIZE=32,indices = test_data_indices4,y = test_y,shuffle_ind=True)\n",
    "val_loader4 = data_loader(BATCH_SIZE=32,indices = val_data_indices4,y = val_y,shuffle_ind=False)\n",
    "c = output_model(emb_dim = 100,learning_rate = 0.05,num_epochs = 2,\n",
    "            id_token_dt = id2token4,train_loader_dt = train_loader4,\n",
    "            test_loader_dt = test_loader4,val_loader_dt=val_loader4)\n",
    "\n",
    "MAX_SENTENCE_LENGTH = 200\n",
    "train_loader4 = data_loader(BATCH_SIZE=32,indices = train_data_indices4,y = train_y,shuffle_ind=True)\n",
    "test_loader4 = data_loader(BATCH_SIZE=32,indices = test_data_indices4,y = test_y,shuffle_ind=True)\n",
    "val_loader4 = data_loader(BATCH_SIZE=32,indices = val_data_indices4,y = val_y,shuffle_ind=False)\n",
    "d = output_model(emb_dim = 200,learning_rate = 0.05,num_epochs = 2,\n",
    "            id_token_dt = id2token4,train_loader_dt = train_loader4,\n",
    "            test_loader_dt = test_loader4,val_loader_dt=val_loader4)\n",
    "\n",
    "dt = pd.DataFrame([a,b,c,d], columns=['emb_dim',\"learning_rate\",\"epochs\",'train_acc','val_acc'])\n",
    "dt.to_csv('msl_4gram.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d7655d9c5f940fea6f914fcaaee06a7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#test learning rate\n",
    "#3gram_10000_lrate\n",
    "learning_rate = [0.005,0.01,0.02, 0.025,0.03,0.035,0.04,0.045,0.05,0.1]\n",
    "r3_lr = []\n",
    "\n",
    "MAX_SENTENCE_LENGTH = 500\n",
    "train_loader3 = data_loader(BATCH_SIZE=32,indices = train_data_indices3,y = train_y,shuffle_ind=True)\n",
    "test_loader3 = data_loader(BATCH_SIZE=32,indices = test_data_indices3,y = test_y,shuffle_ind=True)\n",
    "val_loader3 = data_loader(BATCH_SIZE=32,indices = val_data_indices3,y = val_y,shuffle_ind=False)\n",
    "for j in tqdm_notebook(learning_rate):\n",
    "    temp = output_model(emb_dim = 100,learning_rate = j,num_epochs = 2,\n",
    "                        id_token_dt = id2token3,train_loader_dt = train_loader3,\n",
    "                        test_loader_dt = test_loader3,val_loader_dt=val_loader3)\n",
    "    temp\n",
    "    temp.insert(0,i)\n",
    "    r3_lr.append(temp)\n",
    "\n",
    "dt = pd.DataFrame(r3_lr, columns=['max_voc_len','emb_dim',\"learning_rate\",\"epochs\",'train_acc','val_acc'])\n",
    "dt.to_csv('r3_lr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51d7b55f10f84624a8fc431e3f9837e7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#4gram_10000_lrate\n",
    "r4_lr = []\n",
    "\n",
    "MAX_SENTENCE_LENGTH = 500\n",
    "train_loader4 = data_loader(BATCH_SIZE=32,indices = train_data_indices4,y = train_y,shuffle_ind=True)\n",
    "test_loader4 = data_loader(BATCH_SIZE=32,indices = test_data_indices4,y = test_y,shuffle_ind=True)\n",
    "val_loader4 = data_loader(BATCH_SIZE=32,indices = val_data_indices4,y = val_y,shuffle_ind=False)\n",
    "for j in tqdm_notebook(learning_rate):\n",
    "    temp = output_model(emb_dim = 100,learning_rate = j,num_epochs = 2,\n",
    "                        id_token_dt = id2token4,train_loader_dt = train_loader4,\n",
    "                        test_loader_dt = test_loader4,val_loader_dt=val_loader4)\n",
    "    temp\n",
    "    temp.insert(0,i)\n",
    "    r4_lr.append(temp)\n",
    "\n",
    "dt = pd.DataFrame(r4_lr, columns=['max_voc_len','emb_dim',\"learning_rate\",\"epochs\",'train_acc','val_acc'])\n",
    "dt.to_csv('r4_lr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1ed7151337d489094d51e547c72ead3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#2gram_10000_lrate\n",
    "learning_rate = [0.005,0.01,0.02,0.03,0.035,0.04,0.045,0.05,0.1]\n",
    "r2_lr = []\n",
    "\n",
    "MAX_SENTENCE_LENGTH = 500\n",
    "train_loader2 = data_loader(BATCH_SIZE=32,indices = train_data_indices2,y = train_y,shuffle_ind=True)\n",
    "test_loader2 = data_loader(BATCH_SIZE=32,indices = test_data_indices2,y = test_y,shuffle_ind=True)\n",
    "val_loader2 = data_loader(BATCH_SIZE=32,indices = val_data_indices2,y = val_y,shuffle_ind=False)\n",
    "for j in tqdm_notebook(learning_rate):\n",
    "    temp = output_model(emb_dim = 100,learning_rate = j,num_epochs = 2,\n",
    "                        id_token_dt = id2token2,train_loader_dt = train_loader2,\n",
    "                        test_loader_dt = test_loader2,val_loader_dt=val_loader2)\n",
    "    temp\n",
    "    temp.insert(0,i)\n",
    "    r2_lr.append(temp)\n",
    "\n",
    "dt = pd.DataFrame(r2_lr, columns=['max_voc_len','emb_dim',\"learning_rate\",\"epochs\",'train_acc','val_acc'])\n",
    "dt.to_csv('r2_lr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e2ea6b4b9b2419db53329f8526a8ba9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6993053df4424f08b3164d48475dbf67"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7f6bcfadc8b4197b4bb471d3009a026"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[100, 0.045, 2, 90.33, 83.44]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test vocabulary size\n",
    "PAD_IDX = 0\n",
    "UNK_IDX = 1\n",
    "\n",
    "def build_vocab_size(all_tokens,max_size):\n",
    "    token_counter = Counter(all_tokens)\n",
    "    vocab, count = zip(*token_counter.most_common(max_size))\n",
    "    id2token = list(vocab)\n",
    "    token2id = dict(zip(vocab, range(2,2+len(vocab)))) \n",
    "    id2token = ['<pad>', '<unk>'] + id2token\n",
    "    token2id['<pad>'] = PAD_IDX \n",
    "    token2id['<unk>'] = UNK_IDX\n",
    "    return token2id, id2token\n",
    "\n",
    "def get_dt_indices_voca_size(all_train_dt,token_train_dt,token_test_dt,token_val_dt,max_size):\n",
    "    token2id, id2token = build_vocab_size(all_train_dt,max_size)\n",
    "    train_data_indices = token2index_dataset(token_train_dt,token2id)\n",
    "    test_data_indices = token2index_dataset(token_test_dt,token2id)\n",
    "    val_data_indices = token2index_dataset(token_val_dt,token2id)\n",
    "    return train_data_indices,test_data_indices,val_data_indices, id2token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bb4daaf598a4f02acb29be6d357ff59"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1794e038435a485a9c1171b4faa3eb00"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbd6c52c32ae411396beb258adeb0c0c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c03cc12185174336ba8f33204fb74e32"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74c957cb3bae46ada085862d6339d832"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56f5091431ef40939acd472549ed30bc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86206eff5876495f9c5e8e42ef1d1454"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6c2a4090804425d9d8c357a64e9b32f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22d8d46d3463483d86a295cf7166a04e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ab0f7690b7044d38217bb833efe25da"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82a601a23e904a898cf870c856a7d1f7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c9b59524e494ed4a0a2e13f749d798b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae9ab642d9864580a212a0c295b90eaa"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a32f10be2d814db0893f8886b4754130"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc84fba9b6fc4b8abe911a8c2475f834"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[[5000, 100, 0.045, 2, 92.345, 84.62],\n",
       " [10000, 100, 0.045, 2, 93.47, 87.26],\n",
       " [15000, 100, 0.045, 2, 91.285, 84.7],\n",
       " [20000, 100, 0.045, 2, 93.105, 86.42],\n",
       " [25000, 100, 0.045, 2, 93.69, 87.06]]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#_1 gram_lr = 0.045\n",
    "voca_size = [5000,10000,15000,20000,25000]\n",
    "r_vac1 = []\n",
    "for i in voca_size:\n",
    "    train_data_indices1,test_data_indices1,val_data_indices1,id2token1= get_dt_indices_voca_size(all_train_tokens,token_train,token_test,token_val,voca_size[0])\n",
    "    MAX_SENTENCE_LENGTH = 500\n",
    "    train_loader1 = data_loader(BATCH_SIZE=32,indices = train_data_indices1,y = train_y,shuffle_ind=True)\n",
    "    test_loader1 = data_loader(BATCH_SIZE=32,indices = test_data_indices1,y = test_y,shuffle_ind=True)\n",
    "    val_loader1 = data_loader(BATCH_SIZE=32,indices = val_data_indices1,y = val_y,shuffle_ind=False)\n",
    "    temp = output_model(emb_dim = 100,learning_rate = 0.045,num_epochs = 2,\n",
    "                     id_token_dt = id2token1,train_loader_dt = train_loader1,\n",
    "                     test_loader_dt = test_loader1,val_loader_dt=val_loader1)\n",
    "    temp.insert(0,i)\n",
    "    r_vac1.append(temp)\n",
    "r_vac1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23b411be77034e67ae3682549e43e1cf"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d52e595e67f34e37b68b16e37538a135"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e65a66aca9144caa5041ecd570406c4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9212ef8e7bc2470cb4914a3b406d91b2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a972b5a45bb3462eb03217659d887927"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8c8cb73b25741e0ad987899b4d7e6a4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f88726d38d044527b5e0f584cbb30c15"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acbf4c022d4e47fc8a08a4d4d7514936"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2764317b84584988b0cd1b57d808cbb6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35a7c768e49e490a88c8818e742cfdbc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b9d8d978651460a805da166928f2994"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6d5f2c0e06e47b7bf022440c0b44d36"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad5ed1fc4a4645408a2ce19784d829f5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85d4f4d8dc9b44208350cebfde6ef006"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b464b083716450ea22d53a526d22ee3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[[5000, 100, 0.04, 2, 90.34, 84.44],\n",
       " [10000, 100, 0.04, 2, 93.7, 87.06],\n",
       " [15000, 100, 0.04, 2, 92.705, 85.74],\n",
       " [20000, 100, 0.04, 2, 93.245, 86.54],\n",
       " [25000, 100, 0.04, 2, 93.895, 87.28]]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#_1 gram_lr = 0.04\n",
    "r_vac1_1 = []\n",
    "for i in voca_size:\n",
    "    train_data_indices1,test_data_indices1,val_data_indices1,id2token1= get_dt_indices_voca_size(all_train_tokens,token_train,token_test,token_val,voca_size[0])\n",
    "    MAX_SENTENCE_LENGTH = 500\n",
    "    train_loader1 = data_loader(BATCH_SIZE=32,indices = train_data_indices1,y = train_y,shuffle_ind=True)\n",
    "    test_loader1 = data_loader(BATCH_SIZE=32,indices = test_data_indices1,y = test_y,shuffle_ind=True)\n",
    "    val_loader1 = data_loader(BATCH_SIZE=32,indices = val_data_indices1,y = val_y,shuffle_ind=False)\n",
    "    temp = output_model(emb_dim = 100,learning_rate = 0.04,num_epochs = 2,\n",
    "                     id_token_dt = id2token1,train_loader_dt = train_loader1,\n",
    "                     test_loader_dt = test_loader1,val_loader_dt=val_loader1)\n",
    "    temp.insert(0,i)\n",
    "    r_vac1_1.append(temp)\n",
    "r_vac1_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0854f93764f484581fb9c57fa978147"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d153bc55bd7a4e4eb5ae7ad2e74a7cd8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e07eb04106a74107a0f18809e12d1e27"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2de90bf6bb1245a29ee7b62232a1d72a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46397c03dc9a480b82a4605375960979"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4235ff9081804b40839cb882a347706a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b5980c1663b485e8466493335beaf84"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "789da6cfbbcc487db52770662730b13c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f823235edd84336aa268b73a3f6d039"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8a94aa9e69943c3ba51eef1b1be5a3e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e445851f7a52478481da4606d039bef1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cc2c378e6344e4688e0a8b90848c0c7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "026ce2f284904c61b48b6453737be028"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "275c0410f776473183119d0db875bee5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2633821eb21942cf81f567fabb308431"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[[5000, 200, 0.05, 2, 88.945, 83.7],\n",
       " [10000, 200, 0.05, 2, 92.825, 86.7],\n",
       " [15000, 200, 0.05, 2, 91.88, 85.42],\n",
       " [20000, 200, 0.05, 2, 91.575, 85.02],\n",
       " [25000, 200, 0.05, 2, 92.645, 86.12]]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#_1 gram_lr = 0.05\n",
    "r_vac1_2 = []\n",
    "for i in voca_size:\n",
    "    train_data_indices1,test_data_indices1,val_data_indices1,id2token1= get_dt_indices_voca_size(all_train_tokens,token_train,token_test,token_val,voca_size[0])\n",
    "    MAX_SENTENCE_LENGTH = 500\n",
    "    train_loader1 = data_loader(BATCH_SIZE=32,indices = train_data_indices1,y = train_y,shuffle_ind=True)\n",
    "    test_loader1 = data_loader(BATCH_SIZE=32,indices = test_data_indices1,y = test_y,shuffle_ind=True)\n",
    "    val_loader1 = data_loader(BATCH_SIZE=32,indices = val_data_indices1,y = val_y,shuffle_ind=False)\n",
    "    temp = output_model(emb_dim = 200,learning_rate = 0.05,num_epochs = 2,\n",
    "                     id_token_dt = id2token1,train_loader_dt = train_loader1,\n",
    "                     test_loader_dt = test_loader1,val_loader_dt=val_loader1)\n",
    "    temp.insert(0,i)\n",
    "    r_vac1_2.append(temp)\n",
    "r_vac1_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6216e873e7f4191ae40b1b7f63aab50"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "578ff5a02d994082aa672565fa8b0bb1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5f2e069133046b28f28667f211e915d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fbedbc7e2ce42929099e6ca0b0fd8e7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e4dadc82a1f4cb19162e09dca439f37"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33b9581b62bc425095ef65440ce11ce5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "568735e6e18544278aa993040433b540"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f1cfd2d0ba34415b9a926216532b4b3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3670424cf4c041f1a18936a19e013744"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cbb574f803048ccb5286ca45c7449bb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3bc2982ebbe49c0be843bd206a74ba8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37443163976e404693d60eabc1e4b1e0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1925c876e0084cd1bcb7944805bf8568"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67ee98946c4049be8a461d2466fb18b9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2b03146f46e4b73a5576c6995829dd3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[[5000, 100, 0.045, 2, 91.42, 84.2],\n",
       " [10000, 100, 0.045, 2, 90.205, 83.72],\n",
       " [15000, 100, 0.045, 2, 90.28, 83.5],\n",
       " [20000, 100, 0.045, 2, 91.165, 83.46],\n",
       " [25000, 100, 0.045, 2, 86.525, 80.58]]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#_2 gram_lr = 0.045\n",
    "voca_size = [5000,10000,15000,20000,25000]\n",
    "r_vac2= []\n",
    "for i in voca_size:\n",
    "    train_data_indices2,test_data_indices2,val_data_indices2,id2token2= get_dt_indices_voca_size(all_bigrams_train,bigram_train,bigram_test,bigram_val,voca_size[0])\n",
    "    MAX_SENTENCE_LENGTH = 500\n",
    "    train_loader2 = data_loader(BATCH_SIZE=32,indices = train_data_indices2,y = train_y,shuffle_ind=True)\n",
    "    test_loader2 = data_loader(BATCH_SIZE=32,indices = test_data_indices2,y = test_y,shuffle_ind=True)\n",
    "    val_loader2 = data_loader(BATCH_SIZE=32,indices = val_data_indices2,y = val_y,shuffle_ind=False)\n",
    "    temp = output_model(emb_dim = 100,learning_rate = 0.045,num_epochs = 2,\n",
    "                     id_token_dt = id2token2,train_loader_dt = train_loader2,\n",
    "                     test_loader_dt = test_loader2,val_loader_dt=val_loader2)\n",
    "    temp.insert(0,i)\n",
    "    r_vac2.append(temp)\n",
    "r_vac2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "083d5e2cf0844deeb0888178d3135ea1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c99339f10d242ee974c8a2f6e6e5129"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e3d10ddb7e34f75ba46d815b56f1703"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afe9f291c9b5482197478785ade5eabb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f6c7adda41c4747bdca7be9cbdfae87"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0ff14b7ddaf4c19a70c4791bb767532"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c295999b39f46718bb4d416fa6103f0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fbfa3fee01543d1ab2670e6b0adfdd7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c584e2dd7854b769ff29d583d13a163"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[[100, 0.025, 2, 94.515, 84.78],\n",
       " [100, 0.035, 2, 95.85, 84.8],\n",
       " [100, 0.045, 2, 93.685, 83.32]]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#_2 gram_Adam_lr = 0.025,0.035.0.045\n",
    "lr2 = [0.025,0.035,0.045]\n",
    "r_lr_adam2= []\n",
    "for i in lr2:\n",
    "    train_data_indices2,test_data_indices2,val_data_indices2,id2token2= get_dt_indices_voca_size(all_bigrams_train,bigram_train,bigram_test,bigram_val,10000)\n",
    "    MAX_SENTENCE_LENGTH = 500\n",
    "    train_loader2 = data_loader(BATCH_SIZE=32,indices = train_data_indices2,y = train_y,shuffle_ind=True)\n",
    "    test_loader2 = data_loader(BATCH_SIZE=32,indices = test_data_indices2,y = test_y,shuffle_ind=True)\n",
    "    val_loader2 = data_loader(BATCH_SIZE=32,indices = val_data_indices2,y = val_y,shuffle_ind=False)\n",
    "    temp = output_model(emb_dim = 100,learning_rate = i,num_epochs = 2,\n",
    "                     id_token_dt = id2token2,train_loader_dt = train_loader2,\n",
    "                     test_loader_dt = test_loader2,val_loader_dt=val_loader2)\n",
    "    r_lr_adam2.append(temp)\n",
    "r_lr_adam2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9622713d1b124c7da372b66676755eaa"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "379f93c9864943e495c533632d927185"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7dae265e13a495fa2d4daec13c123f2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e45b2ce495642c685827f5e0b5ac987"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd52de17145e434eadf882714ff6cbf6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcf21c5d4720472293770911df1db468"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ae7276b811e4e51b0f89c973bb3c7c4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31eb943a01d14323bf030380fb4e676e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8772c8a0bcb433c895fa9db10385039"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[[100, 0.025, 2, 92.45, 80.0],\n",
       " [100, 0.035, 2, 85.64, 74.22],\n",
       " [100, 0.045, 2, 93.09, 79.38]]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#_3 gram_Adam_lr = 0.025,0.035,0.045\n",
    "lr3 = [0.025,0.035,0.045]\n",
    "r_lr_adam3= []\n",
    "for i in lr3:\n",
    "    train_data_indices3,test_data_indices3,val_data_indices3,id2token3= get_dt_indices_voca_size(all_trigrams_train,trigram_train,trigram_test,trigram_val,10000)\n",
    "    MAX_SENTENCE_LENGTH = 500\n",
    "    train_loader3 = data_loader(BATCH_SIZE=32,indices = train_data_indices3,y = train_y,shuffle_ind=True)\n",
    "    test_loader3 = data_loader(BATCH_SIZE=32,indices = test_data_indices3,y = test_y,shuffle_ind=True)\n",
    "    val_loader3 = data_loader(BATCH_SIZE=32,indices = val_data_indices3,y = val_y,shuffle_ind=False)\n",
    "    temp = output_model(emb_dim = 100,learning_rate = i,num_epochs = 2,\n",
    "                     id_token_dt = id2token3,train_loader_dt = train_loader3,\n",
    "                     test_loader_dt = test_loader3,val_loader_dt=val_loader3)\n",
    "    r_lr_adam3.append(temp)\n",
    "r_lr_adam3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7910d9675b934c7da7bd655317328078"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a764e0f83ed4006a6a7ba11b563e5d8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01c1bb44f78447278c89ed3ee0ef3ef4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b902228f8e284bbc8a26897da1cfd2b9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7cacbe2224e4304bb67f909c8de93cd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29079412d07c462cab0f962adf8c6972"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0e0d0d9d5b344e1a23f2bb07e627d22"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c7e72ba1a9b47e798fa6eb2c5d73b77"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a57ee759a254c8e89b31c86600a56bd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[[100, 0.025, 2, 88.4, 74.74],\n",
       " [100, 0.035, 2, 82.23, 71.96],\n",
       " [100, 0.045, 2, 84.47, 73.16]]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#_4 gram_Adam_lr = 0.025,0.035,0.045\n",
    "lr4 = [0.025,0.035,0.045]\n",
    "r_lr_adam4= []\n",
    "for i in lr4:\n",
    "    train_data_indices3,test_data_indices3,val_data_indices3,id2token3= get_dt_indices_voca_size(all_quagrams_train,quagram_train,quagram_test,quagram_val,10000)\n",
    "    MAX_SENTENCE_LENGTH = 500\n",
    "    train_loader4 = data_loader(BATCH_SIZE=32,indices = train_data_indices4,y = train_y,shuffle_ind=True)\n",
    "    test_loader4 = data_loader(BATCH_SIZE=32,indices = test_data_indices4,y = test_y,shuffle_ind=True)\n",
    "    val_loader4 = data_loader(BATCH_SIZE=32,indices = val_data_indices4,y = val_y,shuffle_ind=False)\n",
    "    temp = output_model(emb_dim = 100,learning_rate = i,num_epochs = 2,\n",
    "                     id_token_dt = id2token4,train_loader_dt = train_loader4,\n",
    "                     test_loader_dt = test_loader4,val_loader_dt=val_loader4)\n",
    "    r_lr_adam4.append(temp)\n",
    "r_lr_adam4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print test set\n",
    "def test_model_print_example(loader, model):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    pred_val =  []\n",
    "    labellist = []\n",
    "    predictlist = []\n",
    "    for data, lengths, labels in loader:\n",
    "        data_batch, length_batch, label_batch = data, lengths, labels\n",
    "        outputs = F.softmax(model(data_batch, length_batch), dim=1)\n",
    "        predicted = outputs.max(1, keepdim=True)[1]\n",
    "        predictlist.append(predicted)\n",
    "        labellist.append(labels)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels.view_as(predicted)).sum().item()\n",
    "        pred_val.append(predicted)\n",
    "    return (100 * correct / total),pred_val\n",
    "    #return labellist,predictlist\n",
    "\n",
    "def output_model_test(emb_dim,learning_rate,num_epochs,id_token_dt,train_loader_dt,test_loader_dt,val_loader_dt):\n",
    "    model = BagOfWords(len(id_token_dt), emb_dim)\n",
    "    criterion = torch.nn.CrossEntropyLoss()  \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (data, lengths, labels) in enumerate(train_loader_dt):\n",
    "            model.train()\n",
    "            data_batch, length_batch, label_batch = data, lengths, labels\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(data_batch, length_batch)\n",
    "            loss = criterion(outputs, label_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        # validate every 100 iterations\n",
    "            if i > 0 and i % 100 == 0:\n",
    "                # validate\n",
    "                train_acc = test_model(train_loader_dt, model)\n",
    "                val_acc,val_r = test_model_print_example(val_loader_dt, model)\n",
    "                test_acc = test_model(test_loader_dt, model)\n",
    "                #print('Epoch: [{}/{}], Step: [{}/{}], Validation Acc: {}'.format( \n",
    "                #           epoch+1, num_epochs, i+1, len(train_loader_dt), val_acc))\n",
    "    #return [emb_dim,learning_rate,num_epochs,test_model(val_loader_dt, model),test_model(test_loader_dt, model)]\n",
    "    #return [emb_dim,learning_rate,num_epochs,train_acc,val_acc,test_model(test_loader_dt, model)]\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_trained = output_model_test(emb_dim = 200,learning_rate = 0.045,num_epochs = 2,\n",
    "                    id_token_dt = id2token1,train_loader_dt = train_loader1,\n",
    "                    test_loader_dt = test_loader1,val_loader_dt=val_loader1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_model_print(loader, model):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    pred_val =  []\n",
    "    labellist = []\n",
    "    predictlist = []\n",
    "    for data, lengths, labels in loader:\n",
    "        data_batch, length_batch, label_batch = data, lengths, labels\n",
    "        outputs = F.softmax(model(data_batch, length_batch), dim=1)\n",
    "        predicted = outputs.max(1, keepdim=True)[1]\n",
    "        predictlist.append(predicted)\n",
    "        labellist.append(labels)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels.view_as(predicted)).sum().item()\n",
    "        pred_val.append(predicted)\n",
    "    #return (100 * correct / total),pred_val\n",
    "    return labellist,predictlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader1 = data_loader(BATCH_SIZE=1,indices = val_data_indices1,y = val_y,shuffle_ind=False)\n",
    "lablls, predls = test_model_print(val_loader1, model_trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([tensor([1]), tensor([1]), tensor([0]), tensor([0]), tensor([0])],\n",
       " [tensor([[1]]), tensor([[0]]), tensor([[0]]), tensor([[1]]), tensor([[0]])])"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find final result\n",
    "lablls[0:5], predls[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([tensor([1]), tensor([1]), tensor([0]), tensor([0]), tensor([0])],\n",
       " [tensor([[1]]), tensor([[0]]), tensor([[0]]), tensor([[0]]), tensor([[0]])])"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find final result\n",
    "lablls[5:10], predls[5:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('This is surely one of the worst films ever made. Each scene is painful. You will groan at the flimsy attempts at humor, the awkward camera work, the sexism and racism, the ridiculous story line, the wooden acting. Poor Joan Bennett; she is the only one in the movie who is not an embarrassment. In all, dreadful.',\n",
       " 0,\n",
       " \"I caught this movie on Sci-Fi before heading into work. If you've any interest in seeing Dean Cain dive and avoid being enveloped in flames at least a dozen times, this movie is for you. If that doesn't peak your interest, well, I'm afraid you'll wish that YOU were the one about to be enveloped in flames, because this movie is pretty bad. The acting, to begin with, is awful, awful, awful. The characters are all completely obnoxious, and the dialogue is worse than your typical Z-grade, Sci-Fi movie. Towards the end, the movie began to remind me of 'Hollow Man' (complete with escape via elevator shaft), except with a Dragon, not a naked, invisible man. Unlike other similar flicks, however, this one wasn't even awesomely bad...it was just plain bad.\",\n",
       " 0,\n",
       " \"<br /><br />This movie is by far one of my favorites. I saw it while in college in the early 90's, and while I couldn't identify with the thirtysomethings in the film, I felt that the story, characters, and movie in general were top notch. To the people who spoke negatively of Indian Summer, feel free to stick to your overblown Armageddon-type movies and leave the movies with a great, wholesome story to those who can appreciate them.\",\n",
       " 1)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#true pred:\n",
    "val_x[7],val_y[7],val_x[9],val_y[9],val_x[6],val_y[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('I was really excited about seeing this film. I thought finally Australia had made a good film.. but I was wrong.<br /><br />This was the most pathetic attempt at a slasher film ever. I feel sorry for Molly Ringwald having to come all the way to Australia to make an awful movie.<br /><br />The acting was terrible (especially that Australian guy who was trying to speak in an American accent), and the plot was also pretty bad.<br /><br />When I first heard about this film coming out, I thought that the title was pathetic (because it sounds like the cheesy film \"Stab\" in Scream 2), but I was willing to let it slide if it was a good movie.<br /><br />WARNING!!! MAJOR SPOILERS!!!<br /><br />Probably the worst thing about the film was the ending. I was expecting a big surprise about who the killer was.. but the killer wasn\\'t even human.. which turned this realistic slasher film into an awful horror movie.<br /><br />Don\\'t see this film.. you\\'ll probably be disappointed!',\n",
       " 1,\n",
       " 'The Tooth Fairy is about the ghost of an old deformed witch that lures children to her house to get a prize for their loose tooth and then takes their lives. The first few minutes introduce you to the 1949 beginning of the legend of the tooth fairy and then switches to present day. The worn out horror plot is pretty much saved by the solid acting. They could have done without the Hammond brothers and a few other scenes, but overall the gore scenes were bloody but quick which had a minimizing effect. The eye candy is pretty good for both genders. Camera work is good. Dialog is fair but cheesy. I expected the film to be a bare bones, low budget, slasher with very few redeeming factors. I was surprised by the quality of the film.',\n",
       " 0,\n",
       " 'While a 9 might seem like an unusually high score for such a slight film, however, compared to the hundreds and hundreds of series detective films from the 1930s and 40s, this is among the very best and also compares very favorably to Powell\\'s later \"Thin Man\" films. Now this does NOT mean that the film is that similar to the Thin Man movies, as THE KENNEL MURDER CASE is not a comedy but more a traditional mystery-detective film. Now you\\'d think that not having Nora Charles or Asta or a traditional comic sidekick (something found in practically all series detective films) along for fun would be a detriment, but I didn\\'t miss them at all because this was such an exceptionally well-written film--having a genuinely interesting case as well as uniformly excellent performances by all.<br /><br />The film begins at the dog show and is called The KENNEL Murder Case, though this Philo Vance film actually spends little of the time at the dog show and dogs are not a super-important part of the film. Instead, a thoroughly hated man is killed and left in a completely sealed room--an idea repeated in quite a few other detective films (such as CRIME DOCTOR\\'S STRANGEST CASE). However, how all this is explained seems pretty credible and fit together very well--keeping my interest throughout. I sure wish other detective films of the day had as intelligently written plots and exceptional acting as this one. This one is definitely a keeper.',\n",
       " 1)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#false pred:\n",
    "val_x[1],val_y[1],val_x[3],val_y[3],val_x[5],val_y[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11a219d90b624676bcad97d349dec662"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "751be95d384c4877b43d622351428410"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2a5001ef4e24897bef18503832af41e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#test_1_gram_lr = 0.05\n",
    "train_data_indices1,test_data_indices1,val_data_indices1,id2token1= get_dt_indices_voca_size(all_train_tokens,token_train,token_test,token_val,voca_size[0])\n",
    "MAX_SENTENCE_LENGTH = 500\n",
    "train_loader1 = data_loader(BATCH_SIZE=32,indices = train_data_indices1,y = train_y,shuffle_ind=True)\n",
    "test_loader1 = data_loader(BATCH_SIZE=32,indices = test_data_indices1,y = test_y,shuffle_ind=True)\n",
    "val_loader1 = data_loader(BATCH_SIZE=32,indices = val_data_indices1,y = val_y,shuffle_ind=False)\n",
    "temp = output_model_test(emb_dim = 200,learning_rate = 0.05,num_epochs = 2,\n",
    "                    id_token_dt = id2token1,train_loader_dt = train_loader1,\n",
    "                    test_loader_dt = test_loader1,val_loader_dt=val_loader1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a36847cc30b412dab14f837df08cee0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cc3a5ab7f164287890c2891351735c8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aec1890152b3499c9c7c452fd14edfc1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#test_2_gram_lr = 0.05\n",
    "train_data_indices2,test_data_indices2,val_data_indices2,id2token2= get_dt_indices_voca_size(all_bigrams_train,bigram_train,bigram_test,bigram_val,voca_size[0])\n",
    "MAX_SENTENCE_LENGTH = 500\n",
    "train_loader2 = data_loader(BATCH_SIZE=32,indices = train_data_indices2,y = train_y,shuffle_ind=True)\n",
    "test_loader2 = data_loader(BATCH_SIZE=32,indices = test_data_indices2,y = test_y,shuffle_ind=True)\n",
    "val_loader2 = data_loader(BATCH_SIZE=32,indices = val_data_indices2,y = val_y,shuffle_ind=False)\n",
    "temp = output_model_test(emb_dim = 200,learning_rate = 0.05,num_epochs = 2,\n",
    "                    id_token_dt = id2token2,train_loader_dt = train_loader2,\n",
    "                    test_loader_dt = test_loader2,val_loader_dt=val_loader2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[200, 0.05, 2, 90.575, 82.8, 83.476]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46fe94ca7c3d4a1f9dd905779cd32f8e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "758e2e00ab454088ab614db02d9d436c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f3114d9efe040f1ae1bca00e5096b1f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[200, 0.05, 2, 76.915, 70.68, 78.612]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test_3_gram_lr = 0.05\n",
    "train_data_indices3,test_data_indices3,val_data_indices3,id2token3= get_dt_indices_voca_size(all_trigrams_train,trigram_train,trigram_test,trigram_val,voca_size[0])\n",
    "MAX_SENTENCE_LENGTH = 500\n",
    "train_loader3 = data_loader(BATCH_SIZE=32,indices = train_data_indices3,y = train_y,shuffle_ind=True)\n",
    "test_loader3 = data_loader(BATCH_SIZE=32,indices = test_data_indices3,y = test_y,shuffle_ind=True)\n",
    "val_loader3 = data_loader(BATCH_SIZE=32,indices = val_data_indices3,y = val_y,shuffle_ind=False)\n",
    "temp = output_model_test(emb_dim = 200,learning_rate = 0.05,num_epochs = 2,\n",
    "                    id_token_dt = id2token3,train_loader_dt = train_loader3,\n",
    "                    test_loader_dt = test_loader3,val_loader_dt=val_loader3)\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "447a16e0497244649abec64386e319c3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8475944d3ee4e0997a160dacefc6e94"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f7b7fa29cf044eaae65b6290fb081e0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[200, 0.05, 2, 83.965, 71.54, 73.144]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test_4_gram_lr = 0.05\n",
    "train_data_indices3,test_data_indices3,val_data_indices3,id2token3= get_dt_indices_voca_size(all_quagrams_train,quagram_train,quagram_test,quagram_val,voca_size[0])\n",
    "MAX_SENTENCE_LENGTH = 500\n",
    "train_loader4 = data_loader(BATCH_SIZE=32,indices = train_data_indices4,y = train_y,shuffle_ind=True)\n",
    "test_loader4 = data_loader(BATCH_SIZE=32,indices = test_data_indices4,y = test_y,shuffle_ind=True)\n",
    "val_loader4 = data_loader(BATCH_SIZE=32,indices = val_data_indices4,y = val_y,shuffle_ind=False)\n",
    "temp = output_model_test(emb_dim = 200,learning_rate = 0.05,num_epochs = 2,\n",
    "                    id_token_dt = id2token4,train_loader_dt = train_loader4,\n",
    "                    test_loader_dt = test_loader4,val_loader_dt=val_loader4)\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5b0b1abe74e4fdd87e948cb96c3e8e8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce02aa157d3d473f8963c31b5d3685a1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9126729595794b4d96ae11871840e2c3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[200, 0.045, 2, 92.615, 86.54, 86.364]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test_1_gram_lr = 0.045\n",
    "train_data_indices1,test_data_indices1,val_data_indices1,id2token1= get_dt_indices_voca_size(all_train_tokens,token_train,token_test,token_val,voca_size[0])\n",
    "MAX_SENTENCE_LENGTH = 500\n",
    "train_loader1 = data_loader(BATCH_SIZE=32,indices = train_data_indices1,y = train_y,shuffle_ind=True)\n",
    "test_loader1 = data_loader(BATCH_SIZE=32,indices = test_data_indices1,y = test_y,shuffle_ind=True)\n",
    "val_loader1 = data_loader(BATCH_SIZE=32,indices = val_data_indices1,y = val_y,shuffle_ind=False)\n",
    "temp = output_model_test(emb_dim = 200,learning_rate = 0.045,num_epochs = 2,\n",
    "                    id_token_dt = id2token1,train_loader_dt = train_loader1,\n",
    "                    test_loader_dt = test_loader1,val_loader_dt=val_loader1)\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60d38643c9b647ec844c0ed55593e46a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fc2f22cbfce4465b8485d1b2a02b55a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b554c3a4db15446992071049a7418e54"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[200, 0.05, 2, 81.41, 77.08, 83.764]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test_2_gram_lr = 0.045\n",
    "train_data_indices2,test_data_indices2,val_data_indices2,id2token2= get_dt_indices_voca_size(all_bigrams_train,bigram_train,bigram_test,bigram_val,voca_size[0])\n",
    "MAX_SENTENCE_LENGTH = 500\n",
    "train_loader2 = data_loader(BATCH_SIZE=32,indices = train_data_indices2,y = train_y,shuffle_ind=True)\n",
    "test_loader2 = data_loader(BATCH_SIZE=32,indices = test_data_indices2,y = test_y,shuffle_ind=True)\n",
    "val_loader2 = data_loader(BATCH_SIZE=32,indices = val_data_indices2,y = val_y,shuffle_ind=False)\n",
    "temp = output_model_test(emb_dim = 200,learning_rate = 0.05,num_epochs = 2,\n",
    "                    id_token_dt = id2token2,train_loader_dt = train_loader2,\n",
    "                    test_loader_dt = test_loader2,val_loader_dt=val_loader2)\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "218170baefb847e78499ffc68fdcb763"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e6ab868f59c436ca04544ada05bcc1e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c93860a5233749b9823ca3d255a42296"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[200, 0.045, 2, 76.14, 69.88, 76.356]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test_3_gram_lr = 0.045\n",
    "train_data_indices3,test_data_indices3,val_data_indices3,id2token3= get_dt_indices_voca_size(all_trigrams_train,trigram_train,trigram_test,trigram_val,voca_size[0])\n",
    "MAX_SENTENCE_LENGTH = 500\n",
    "train_loader3 = data_loader(BATCH_SIZE=32,indices = train_data_indices3,y = train_y,shuffle_ind=True)\n",
    "test_loader3 = data_loader(BATCH_SIZE=32,indices = test_data_indices3,y = test_y,shuffle_ind=True)\n",
    "val_loader3 = data_loader(BATCH_SIZE=32,indices = val_data_indices3,y = val_y,shuffle_ind=False)\n",
    "temp = output_model_test(emb_dim = 200,learning_rate = 0.045,num_epochs = 2,\n",
    "                    id_token_dt = id2token3,train_loader_dt = train_loader3,\n",
    "                    test_loader_dt = test_loader3,val_loader_dt=val_loader3)\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e48697c3da3d4722a36ccd75acc5fe94"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b89efc7ca7a5496ea813b27990af8dc0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76f2acc896f04b49a3384de94dcb2af0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[200, 0.045, 2, 88.945, 74.64, 74.28]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test_4_gram_lr = 0.045\n",
    "train_data_indices3,test_data_indices3,val_data_indices3,id2token3= get_dt_indices_voca_size(all_quagrams_train,quagram_train,quagram_test,quagram_val,voca_size[0])\n",
    "MAX_SENTENCE_LENGTH = 500\n",
    "train_loader4 = data_loader(BATCH_SIZE=32,indices = train_data_indices4,y = train_y,shuffle_ind=True)\n",
    "test_loader4 = data_loader(BATCH_SIZE=32,indices = test_data_indices4,y = test_y,shuffle_ind=True)\n",
    "val_loader4 = data_loader(BATCH_SIZE=32,indices = val_data_indices4,y = val_y,shuffle_ind=False)\n",
    "temp = output_model_test(emb_dim = 200,learning_rate = 0.045,num_epochs = 2,\n",
    "                    id_token_dt = id2token4,train_loader_dt = train_loader4,\n",
    "                    test_loader_dt = test_loader4,val_loader_dt=val_loader4)\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
